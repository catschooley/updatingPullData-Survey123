{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Minerals Pull Data for Minerals Field Inspections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cat Schooley  \n",
    "GIS Analyst  \n",
    "October 25, 2021\n",
    "\n",
    "The Division of Oil, Gas, and Mining uses the ESRI product Survey123 in our field inspections. This application creates a streamlined workflow for conducting complicated inspections in the field and connecting them with databases back in the office and on the AGOL cloud server. \n",
    "\n",
    "One of the capabilities of Survey123 is a feature called 'Pull Data'. I should note this is only available in Survey123 Connect, not the online survey creator. Pull data allows the creators of the survey to connect a seperate csv file to the backend of the survey that the survey can then pull information from to make the inspector's jobs easier. For the minerals inspections the pull data table contains all the information for a mine (permit number, operator, etc.), but the inspector only has to input the permit number in the actual survey. Thanks to the pull data table all other mine information is autofilled and the inspector can get right to work on the inspection itself. It may seem miniscle, but this approach leads to less errors caused by typos, provides up-to-date information that the inspector might not know. Also a minute saved at the beginning of each survey adds up. \n",
    "\n",
    "I'll break down the code and why it's written the way it is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling Data into the Python Script <br>\n",
    "\n",
    "For the minerals inspections the pull data comes from the FoxPro database (may have changed since time this was written). When a new mine is permitted, one is retired, bond amounts change or anything else is changed about a mine, this database is where those changes are stored. One of our inspectors (Kim Courbon at the time of this writing), takes data from the FoxPro database and saves it into a Google Sheet. This google sheet is easily shared but an issue occurs when she makes any changes. Due to the old software used in FoxPro, Kim has to completely overwrite the google sheet which changes the sheet's id. See the highlighted section below. \n",
    "\n",
    "    docs .google.com /spreadsheets/d/{SPREADSHEETID}/export? \n",
    "    format=csv&id{SPREADSHEETID}&`**gid=2113599541**` < Notice this section here\n",
    "\n",
    "Though it is possible to pull down a google sheet as a csv to use in a python script, if this google sheet is overwritten often, you'll have to go a different route. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, pull in the module you need for the script. For the first part of this script we use the pandas module. Pandas is often pulled in as pd. I'm not sure why, but it's what we do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import modules ###\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull Data sheet directly from Google Sheet using the url <br>\n",
    "\n",
    "First, I'll show you how to pull directly from the google sheet. As stated above, this doesn't work well for this example but can be used for other workflows. To do this you have to write the url the same as the url when exporting the google sheet to a csv. Google has been known to change this formatting though so if it doesn't work check out <a href=\"https://stackoverflow.com/\"> Stack Overflow</a> or other online resources for an updated version. \n",
    "\n",
    "When you visit the google sheet you'll see a url that looks like this:\n",
    "\n",
    "```python\n",
    "https://docs.google.com/spreadsheets/d/{SPREADSHEETID}/edit#gid=2113599541\n",
    "```\n",
    "\n",
    "You will have to insert this between the spreadsheet id and the page id: \n",
    "```python\n",
    "/export?format=csv&id{SPREADSHEETID}&\n",
    "```\n",
    "\n",
    "In order to get this final url to use in the code:\n",
    "\n",
    "```python\n",
    "https://docs.google.com/spreadsheets/d/{SPREADSHEETID}/export?format=csv&id{SPREADSHEETID}&gid=2113599541\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the url we need we can go ahead and code it in.\n",
    "\n",
    "```python\n",
    "url = \"https://docs.google.com/spreadsheets/d/{SPREADSHEETIDENTIFIER}/export?format=csv&id{SPREADSHEETIDENTIFIER}&gid=2113599541\"\n",
    "```\n",
    "\n",
    "I'm selecting for the columns that I want and not filtering out any NA values\n",
    "```python\n",
    "df = pd.read_csv(url, dtype = object, usecols= [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], na_filter = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull Data from local Google Drive Desktop location <br>\n",
    "\n",
    "Now I'm going to show you how to do it using <a href= \"https://www.google.com/drive/download/\">Google Drive Desktop</a> which circumvents the issue of a changing page id. From this point forward, you can run all the cells to run the script as we go along, simply change the file name and information to your computer's location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-500760ac1848>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Here I call the file, the sheet from the workbook, the dtype for the dataframe and the columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"For Pull Data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_filter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# This is a bit redundant but makes sure that the data in the dataframe is read as a 'string'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# This is my T:/ Drive, where the excel workbook is saved\n",
    "\n",
    "file = 'T:/My Drive/FoxProLinked4.xlsm'\n",
    "\n",
    "# Here I call the file, the sheet from the workbook, the dtype for the dataframe and the columns \n",
    "\n",
    "df = pd.read_excel(file, sheet_name=\"For Pull Data\", dtype = str, usecols= [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], na_filter = False, index_col= None)\n",
    "\n",
    "# This is a bit redundant but makes sure that the data in the dataframe is read as a 'string'\n",
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Whitespaces and commas <br>\n",
    "\n",
    "When data is pulled into pandas you should do a cleaning of the data. Python is sensitive to white spaces and tables can be sensitive to some special characters such as commas in the case of csvs. Keep that in mind whenever performing tasks like this. \n",
    "\n",
    "`str.strip` is used in the function below. This is why it was so important to have the data in the dataframe read as a string. Now you'll see if you were to use `df.dtypes` you would see that each field is of dtype object. This is because there's some columns in FoxPro that have both numbers and letters as well as some columns with large empty spaces. There is also a total row that appears at the bottom. All of these make it difficult for pandas to know if these of of type `str`, `int`, or something else so it chooses the catch-all `object`. Since we have the dataframe reading as a string, we can use the `.str` function and `.replace` function to clean up our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitespaceRemover(dataframe):\n",
    "    \n",
    "    # iterating over the columns\n",
    "    for i in dataframe.columns:\n",
    "          \n",
    "        # checking datatype of each columns\n",
    "        if dataframe[i].dtype == 'object': #helps pinpoint if something is wrong with the data type\n",
    "              \n",
    "            # applying strip function on column\n",
    "            dataframe[i] = dataframe[i].map(str.strip)\n",
    "            \n",
    "            dataframe[i] = dataframe[i].str.replace(\",\",\"\")\n",
    "            \n",
    "        else:\n",
    "              \n",
    "            # if condn. is False then it will do nothing.\n",
    "            pass\n",
    "            \n",
    "            print(f\"{i} was skipped because field value was not a string\")\n",
    "        \n",
    "### End Function ###\n",
    "\n",
    "print(\"Commas and whitespaces being removed...\")\n",
    "\n",
    "whitespaceRemover(df) # plug your dataframe into function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwriting Pull Data <br>\n",
    "\n",
    "After it's clean we can write it to a csv file overwriting the previous pull data table in your survey. Notice the location of I am writing the new csv to. The Media folder holds items used in various ArcGIS Survey123 workflows. The Media folder can contain offline basemaps that survey authors want downloaded with a specific survey in the ArcGIS Survey123 Field App. Additional workflows that use the Media folder include image questions that use the draw and annotate appearance, or consuming images directly in your survey. \n",
    "\n",
    "Please note that all care should be taken to ensure the files you are updating with this script have the exact name as the files in the originally published media folder. Also, the files should have the same format, with the same field names as the original files (in the case of CSV files). Only rows of data should be updated or additional rows added. If you want to change the format of the files (rename or add columns) you should update the files via Connect in the media folder, update the survey XLSForm, and then re-publish the survey to ensure the changes do not break anything.\n",
    "\n",
    "It is recommended to test the script on a backup copy of your survey and ensure the survey can be downloaded and updated in the field app, checking that the external choice lists and/or media items are working as expected. This should be confirmed before running the script and updating the media folder and files on your real survey that is currently in use by other ArcGIS Survey123 Field App users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overwriting old Minerals Pulldata with cleaned Minerals Pulldata...\")\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\cschooley\\ArcGIS\\My Survey Designs\\PullUpdate\\MineralsPulldata.csv\", index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing Survey123 Pull Data with Local Update\n",
    "\n",
    "To start we will import the required modules and define our variables.<br>\n",
    "**Please format folder directories as C:/Users/username… include a trailing slash after the final folder name as the updated file directory is concatenated to the updated file name**\n",
    "\n",
    "\n",
    "The variables are defined as follows: \n",
    "\n",
    "* **portalURL** - The URL for your WebGIS Portal (ex. www.arcgis.com)\n",
    "* **username** - Your WebGIS Portal username (ex. gisadmin)\n",
    "* **password** - You WebGIS Portal password (ex. gisadmin1)\n",
    "* **itemID** - The Item ID for the ArcGIS Survey123 Form Item in you WebGIS Portal (ex. 89bc8c7844e548e09baa3aad4695e78b)\n",
    "* **download_folder** - The folder directory you would like the Survey123 Form Item to be downloaded with the trailing slash (ex. C:/temp/)\n",
    "* **updated_file** - The updated file name containing the extension (ex. myphoto.png)\n",
    "* **source_loc** - Folder directory where the updated file is located (ex. C:/users/username/arcgis/my survey designs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modules ###\n",
    "\n",
    "import arcgis\n",
    "from arcgis.gis import GIS\n",
    "import zipfile\n",
    "import shutil\n",
    "import arcpy\n",
    "import os\n",
    "\n",
    "token = arcpy.GetSigninToken()\n",
    "if token is not None:\n",
    "    print(token['token'])\n",
    "\n",
    "portalURL = r'https://arcgis.com'\n",
    "username = 'OGMGIS_utahDNR'\n",
    "password = 'MiningData801'\n",
    "itemID = 'd1d980978a0e440fb371afbee891f80c'  #'5a5dbe18e9554e8185b87b137d66318a' Form 1     #'d1d980978a0e440fb371afbee891f80c' Real Mineral Survey ID\n",
    "download_folder = r'C:/temp/'\n",
    "updated_file = r'MineralsPulldata.csv'\n",
    "source_loc = r'C:\\Users\\cschooley\\ArcGIS\\My Survey Designs\\PullUpdate/'\n",
    "\n",
    "\n",
    "### Connect to GIS ###\n",
    "\n",
    "gis = GIS(portalURL, username, password, verify_cert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the survey\n",
    "\n",
    "We will start by grabbing the properties of the Survey123 Form Item. These properties are used later when we update the Form Item with a zip file containing the new media content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_manager = arcgis.apps.survey123.SurveyManager(gis)\n",
    "surveyId = survey_manager.get(itemID)\n",
    "surveyProp = surveyId.properties\n",
    "\n",
    "# Find the Form item in the gis and download as a zip file to the *download_folder* directory.\n",
    "\n",
    "itm = arcgis.gis.Item(gis,itemID)\n",
    "print(itm)\n",
    "savedZip = itm.download(save_path=download_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the zip file to an *`_extracted`* folder in the download location.\n",
    "This *`_extracted`* folder is where the updated media files will be copied and rezipped later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractZIP(filename,folder):\n",
    "    zfile = zipfile.ZipFile(filename)\n",
    "    zfile.extractall(folder)\n",
    "\n",
    "extractZIP(savedZip, download_folder + \"_extracted/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the updated file to the media folder replacing the old file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = source_loc + updated_file\n",
    "dest_file = download_folder + \"_extracted/esriinfo/media/\" + updated_file\n",
    "shutil.copyfile(source_file, dest_file)\n",
    "print (updated_file + \" updated to: \" + download_folder + \"_extracted/esriinfo/media/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the old zip file that was previously downloaded. This will prevent any namespace issues and ensure the process of zipping and uploading the updated survey goes smoothly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(savedZip)\n",
    "print (\"Old zip file deleted from: \" + download_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the updated survey<br>\n",
    "\n",
    "We will now zip the updated survey and place it in the download folder. The code below grabs the survey title from the survey properties and passes it into the function which zips the updated survey contents to the download folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipFileName = surveyProp['title']\n",
    "os.chdir(download_folder)\n",
    "updateZip = shutil.make_archive(zipFileName, 'zip', download_folder + '_extracted/')\n",
    "print (updateZip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the new zip file and update the Form Item with the new Media folder content.\n",
    "\n",
    "Then, clean up intermediate data. This process will delete the updated zip file as well as the extracted folder containing the unzipped survey content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itm.update({},updateZip)\n",
    "\n",
    "os.remove(updateZip)\n",
    "print (zipFileName + \" deleted from: \" + download_folder)\n",
    "\n",
    "shutil.rmtree(download_folder + \"_extracted/\")\n",
    "print (\"extracted folder deleted from: \" + download_folder)\n",
    "print (zipFileName + \" successfully updated with \" + source_file + \" and uploaded to your ArcGIS portal!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Email Notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modules ###\n",
    "\n",
    "import yagmail\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Sending Emails...\")\n",
    "now = datetime.now()\n",
    "date = now.strftime(\"%m/%d/%Y\")\n",
    "time = now.strftime(\"%I:%M:%S %p\")\n",
    "reciever = ['cschooley@utah.gov', 'michaelvanhatten@utah.gov', 'kcoburn@utah.gov']\n",
    "body = f'Hello,\\n\\nThe Mineral Pulldata for {zipFileName} survey successfully updated with the latest Pulldata available as of {date} and uploaded to OGMGIS_utahDNR admin account!\\n\\nCompleted on {date} at {time}.\\n\\nThank you!'\n",
    "yag = yagmail.SMTP(\"utahogmgisupdates@gmail.com\", 'OGMG!Sutah801')\n",
    "for recipient in reciever:\n",
    "    yag.send(\n",
    "        to=recipient,\n",
    "        subject='Minerals Pulldata Update',\n",
    "        contents = body\n",
    "    )\n",
    "\n",
    "print('Emails sent successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "#################################### Remove Commas and Trailing/Leading Spaces from CSV ##############################\n",
    "\n",
    "### import modules ###\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "### Read CSV from Google Sheets #\n",
    "\n",
    "### Pull Data sheet directly from Kim's FoxProLinked4\n",
    "\n",
    "# url = \"https://docs.google.com/spreadsheets/d/1abAxgx3VfBJLwPhPtlItr3gR85IUYuAQ/export?format=csv&id=1abAxgx3VfBJLwPhPtlItr3gR85IUYuAQ&gid=2113599541\"\n",
    "\n",
    "# select for the columns needed for Pulldata csv\n",
    "# df = pd.read_csv(url, dtype = object, usecols= [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], na_filter = False)\n",
    "\n",
    "# Read from local excel workbook synced with Google Drive\n",
    "\n",
    "file = 'T:/My Drive/FoxProLinked4.xlsm'\n",
    "\n",
    "df = pd.read_excel(file, sheet_name=\"For Pull Data\", dtype = str, usecols= [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], na_filter = False, index_col= None)\n",
    "\n",
    "df = df.astype(str)\n",
    "\n",
    "### Function to remove whitespaces (removes leading and trailing spaces) ###\n",
    "\n",
    "# Creating a function which will remove extra leading \n",
    "# and tailing whitespace from the data.\n",
    "# pass dataframe as a parameter here\n",
    "\n",
    "def whitespaceRemover(dataframe):\n",
    "    \n",
    "    # iterating over the columns\n",
    "    for i in dataframe.columns:\n",
    "          \n",
    "        # checking datatype of each columns\n",
    "        if dataframe[i].dtype == 'object':\n",
    "              \n",
    "            # applying strip function on column\n",
    "            dataframe[i] = dataframe[i].map(str.strip)\n",
    "            \n",
    "            dataframe[i] = dataframe[i].str.replace(\",\",\"\")\n",
    "            \n",
    "        else:\n",
    "              \n",
    "            # if condn. is False then it will do nothing.\n",
    "            pass\n",
    "            \n",
    "            print(f\"{i} was skipped because field value was not a string\")\n",
    "        \n",
    "### End Function ###\n",
    "\n",
    "print(\"Commas and whitespaces being removed...\")\n",
    "\n",
    "whitespaceRemover(df) # plug your dataframe into function\n",
    "\n",
    "### Write to new csv ###\n",
    "                  \n",
    "print(\"Overwriting old Minerals Pulldata with cleaned Minerals Pulldata...\")\n",
    "\n",
    "### Due to the requirement to zip and unzip files, this has to be on someone's PC instead of on a cloud server\n",
    "### This could be worked around if there was an API we could use for zipping and unzipping maybe... Beyond my\n",
    "### knowledge but worth looking into further if we would like\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\cschooley\\ArcGIS\\My Survey Designs\\PullUpdate\\MineralsPulldata.csv\", index = False) # Use full path, same name as previous pulldata used in survey\n",
    "\n",
    "################################## Update Pulldata for Minerals ############################\n",
    "\n",
    "# The Media folder holds items used in various ArcGIS Survey123 workflows.\n",
    "# The Media folder can contain offline basemaps that survey authors want downloaded with a specific survey in the ArcGIS Survey123 Field App.\n",
    "# Additional workflows that use the Media folder include image questions that use the draw and annotate appearance,\n",
    "# or consuming images directly in your survey. \n",
    "# As data and workflows advance, it's common that folks want to update the information in the media folder,\n",
    "# but do not want to re-publish their survey every time there are changes to a file.\n",
    "# This sample notebook automates the task of updating the contents in the media folder associated with a published survey. \n",
    "# \n",
    "# **IMPORTANT**: Please note that all care should be taken to ensure the files you are updating with this script have\n",
    "# the exact name as the files in the originally published media folder.\n",
    "# Also, the files should have the same format, with the same field names as the original files (in the case of CSV files).\n",
    "# Only rows of data should be updated or additional rows added.\n",
    "# If you want to change the format of the files (rename or add columns) you should update the files\n",
    "# via Connect in the media folder, update the survey XLSForm,\n",
    "# and then re-publish the survey to ensure the changes do not break anything.\n",
    "# \n",
    "# It is recommended to test the script on a backup copy of your survey and ensure the survey\n",
    "# can be downloaded and updated in the field app, checking that the external choice lists and/or media items are working\n",
    "# as expected. This should be confirmed before running the script and updating the media folder and files on your real\n",
    "# survey that is currently in use by other ArcGIS Survey123 Field App users.\n",
    "# \n",
    "# **Note**: To use this notebook as a python script, check **Insert link HERE**.\n",
    "# Running this script from Windows Task Scheduler or ArcGIS Pro scheduled tools are effective for workflows\n",
    "# that require regular updates. \n",
    "# \n",
    "# To start we will import the required modules and define our variables.\n",
    "# **Please format folder directories as C:/Users/username… include a trailing slash after the final folder\n",
    "# name as the updated file directory is concatenated to the updated file name**.\n",
    "# \n",
    "# The variables are defined as follows: \n",
    "# \n",
    "# * **portalURL** - The URL for your WebGIS Portal (ex. www.arcgis.com)\n",
    "# * **username** - Your WebGIS Portal username (ex. gisadmin)\n",
    "# * **password** - You WebGIS Portal password (ex. gisadmin1)\n",
    "# * **itemID** - The Item ID for the ArcGIS Survey123 Form Item in you WebGIS Portal (ex. 89bc8c7844e548e09baa3aad4695e78b)\n",
    "# * **download_folder** - The folder directory you would like the Survey123 Form Item to be downloaded with the trailing slash (ex. C:/temp/)\n",
    "# * **updated_file** - The updated file name containing the extension (ex. myphoto.png)\n",
    "# * **source_loc** - Folder directory where the updated file is located (ex. C:/users/username/arcgis/my survey designs/)\n",
    "\n",
    "### import modules ###\n",
    "\n",
    "import arcgis\n",
    "from arcgis.gis import GIS\n",
    "import zipfile\n",
    "import shutil\n",
    "import arcpy\n",
    "\n",
    "token = arcpy.GetSigninToken()\n",
    "if token is not None:\n",
    "    print(token['token'])\n",
    "\n",
    "portalURL = r'https://arcgis.com'\n",
    "username = 'OGMGIS_utahDNR'\n",
    "password = 'MiningData801'\n",
    "itemID = 'd1d980978a0e440fb371afbee891f80c'  #'5a5dbe18e9554e8185b87b137d66318a' Form 1     #'d1d980978a0e440fb371afbee891f80c' Real Mineral Survey ID\n",
    "download_folder = r'C:/temp/'\n",
    "updated_file = r'MineralsPulldata.csv'\n",
    "source_loc = r'C:\\Users\\cschooley\\ArcGIS\\My Survey Designs\\PullUpdate/'\n",
    "\n",
    "\n",
    "### Connect to GIS ###\n",
    "\n",
    "gis = GIS(portalURL, username, password, verify_cert=False)\n",
    "\n",
    "\n",
    "# ## Download the survey\n",
    "# \n",
    "# We will start by grabbing the properties of the Survey123 Form Item.\n",
    "# These properties are used later when we update the Form Item with a zip file containing the new media content.\n",
    "\n",
    "survey_manager = arcgis.apps.survey123.SurveyManager(gis)\n",
    "surveyId = survey_manager.get(itemID)\n",
    "surveyProp = surveyId.properties\n",
    "\n",
    "# Find the Form item in the gis and download as a zip file to the *download_folder* directory.\n",
    "\n",
    "itm = arcgis.gis.Item(gis,itemID)\n",
    "print(itm)\n",
    "savedZip = itm.download(save_path=download_folder)\n",
    "\n",
    "\n",
    "# Extract the zip file to an *`_extracted`* folder in the download location.\n",
    "# This *`_extracted`* folder is where the updated media files will be copied and rezipped later on. \n",
    "\n",
    "\n",
    "def extractZIP(filename,folder):\n",
    "    zfile = zipfile.ZipFile(filename)\n",
    "    zfile.extractall(folder)\n",
    "\n",
    "extractZIP(savedZip, download_folder + \"_extracted/\")\n",
    "\n",
    "\n",
    "# Copy the updated file to the media folder replacing the old file. \n",
    "\n",
    "source_file = source_loc + updated_file\n",
    "dest_file = download_folder + \"_extracted/esriinfo/media/\" + updated_file\n",
    "shutil.copyfile(source_file, dest_file)\n",
    "print (updated_file + \" updated to: \" + download_folder + \"_extracted/esriinfo/media/\")\n",
    "\n",
    "\n",
    "# Delete the old zip file that was previously downloaded. This will prevent any namespace issues and ensure the\n",
    "# process of zipping and uploading the updated survey goes smoothly. \n",
    "\n",
    "os.remove(savedZip)\n",
    "print (\"Old zip file deleted from: \" + download_folder)\n",
    "\n",
    "\n",
    "# ## Upload the updated survey\n",
    "# \n",
    "# We will now zip the updated survey and place it in the download folder. The code below grabs the survey title from\n",
    "# the survey properties and passes it into the function which zips the updated survey contents to the download folder.\n",
    "\n",
    "zipFileName = surveyProp['title']\n",
    "os.chdir(download_folder)\n",
    "updateZip = shutil.make_archive(zipFileName, 'zip', download_folder + '_extracted/')\n",
    "print (updateZip)\n",
    "\n",
    "\n",
    "# Upload the new zip file and update the Form Item with the new Media folder content.\n",
    "\n",
    "itm.update({},updateZip)\n",
    "\n",
    "# Clean up intermediate data. This process will delete the updated zip file as well as the extracted folder\n",
    "# containing the unzipped survey content.\n",
    "\n",
    "os.remove(updateZip)\n",
    "print (zipFileName + \" deleted from: \" + download_folder)\n",
    "\n",
    "shutil.rmtree(download_folder + \"_extracted/\")\n",
    "print (\"extracted folder deleted from: \" + download_folder)\n",
    "print (zipFileName + \" successfully updated with \" + source_file + \" and uploaded to your ArcGIS portal!\")\n",
    "\n",
    "################### Send Email Notifications ####################\n",
    "\n",
    "import yagmail\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Sending Emails...\")\n",
    "now = datetime.now()\n",
    "date = now.strftime(\"%m/%d/%Y\")\n",
    "time = now.strftime(\"%I:%M:%S %p\")\n",
    "reciever = ['cschooley@utah.gov', 'michaelvanhatten@utah.gov', 'kcoburn@utah.gov']\n",
    "body = f'Hello,\\n\\nThe Mineral Pulldata for {zipFileName} survey successfully updated with the latest Pulldata available as of {date} and uploaded to OGMGIS_utahDNR admin account!\\n\\nCompleted on {date} at {time}.\\n\\nThank you!'\n",
    "yag = yagmail.SMTP(\"utahogmgisupdates@gmail.com\", 'OGMG!Sutah801')\n",
    "for recipient in reciever:\n",
    "    yag.send(\n",
    "        to=recipient,\n",
    "        subject='Minerals Pulldata Update',\n",
    "        contents = body\n",
    "    )\n",
    "\n",
    "print('Emails sent successfully.')\n",
    "\n",
    "# %%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
