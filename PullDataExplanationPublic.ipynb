{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Minerals Pull Data for Minerals Field Inspections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cat Schooley  \n",
    "GIS Analyst  \n",
    "November 5, 2021\n",
    "\n",
    "### Using Pull Data\n",
    "\n",
    "One of the capabilities of Survey123 is a feature called 'Pull Data'. I should note this is only available in Survey123 Connect, not the online survey creator. Pull data allows the creators of the survey to connect a seperate CSV file to the backend of the survey that the survey can then pull information from. The pull data allows a sort of auto-fill feature to be used. A user can input one piece of information, say an email address, and the survey will grab all the other information related to that survey (name, address, phone number, etc.) and fill it in. This has to be coded into the XLS file of course. It may seem miniscle, but this approach leads to less errors caused by typos, provides up-to-date information (if the CSV is updated regularly). Also a minute saved at the beginning of each survey adds up. \n",
    "\n",
    "I'll break down the code and why it's written the way it is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling Data into the Python Script <br>\n",
    "\n",
    "Google sheets has become more and more widely used as the standard for sharing of information formally stored in programs like Microsoft Excel. It's on the cloud, easy to use, easy to collaborate, and easy to track changes. Where this can be problematic is pulling it into scripts that aren't Google Scripts. There is a Google API that makes this easier, but requires a subscription for some functions. There is a grace credit amount ($200) for the Google Sheets API, then you are billed for any credit use after that. My organization at this time is not a fan of this and therefore has a block to using the Google APIs. For more information on the Google Sheets API check this <a href= \"https://apipheny.io/google-sheets-api/\">link</a> .\n",
    "\n",
    "Due to this rescriction, I have to use a work around. When you use the export capabilities of Google Sheets, there is a hidden URL (I use hidden loosely). At the time of this writing it looks something like this for exporting CSVs from the web. \n",
    "\n",
    "    docs.google.com/spreadsheets/d/{SPREADSHEETID}/export?format=csv&id{SPREADSHEETID}&`**gid=2113599541**` < Notice this section here\n",
    "\n",
    "The gid refers to the sheet id and this changes if a Google Sheet is completely overwritten. This is often done by people using the Google Drive Desktop. They go in and just overwrite the whole thing instead of making changes to the sheet itself. If this gid changes, your code will no longer work. I'm sure this isn't a common issue but I ran into so I found a different route.\n",
    "I'll go over both routes below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, pull in the module you need for the script. For the first part of this script we use the pandas module. Pandas is often pulled in as pd. I'm not sure why, but it's what we do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import modules ###\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull Data sheet directly from Google Sheet using the url <br>\n",
    "\n",
    "First, I'll show you how to pull directly from the web. As stated above, this doesn't work well for my use case but can be used for other workflows. To do this you have to write the url the same as the url when exporting the google sheet to a CSV. Google has been known to change this formatting though so if it doesn't work check out <a href=\"https://stackoverflow.com/\"> Stack Overflow</a> or other online resources for an updated version. \n",
    "\n",
    "When you visit the google sheet you'll see a url that looks like this:\n",
    "\n",
    "```python\n",
    "\"https://docs.google.com/spreadsheets/d/{SPREADSHEETID}/edit#gid=2113599541\"\n",
    "```\n",
    "\n",
    "You will have to insert this between the spreadsheet id and the page id: \n",
    "```python\n",
    "\"/export?format=csv&id{SPREADSHEETID}&\"\n",
    "```\n",
    "\n",
    "In order to get this final url to use in the code:\n",
    "\n",
    "```python\n",
    "\"https://docs.google.com/spreadsheets/d/{SPREADSHEETID}/export?format=csv&id{SPREADSHEETID}&gid=2113599541\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the url we need we can go ahead and code it in.\n",
    "\n",
    "```python\n",
    "url = \"https://docs.google.com/spreadsheets/d/{SPREADSHEETIDENTIFIER}/export?format=csv&id{SPREADSHEETIDENTIFIER}&gid=2113599541\"\n",
    "```\n",
    "\n",
    "I'm selecting for the columns that I want and not filtering out any NA values\n",
    "```python\n",
    "df = pd.read_csv(url, dtype = object, usecols= [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], na_filter = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull Data from local Google Drive Desktop location <br>\n",
    "\n",
    "Now I'm going to show you how to do it using <a href= \"https://www.google.com/drive/download/\">Google Drive Desktop</a> which circumvents the issue of a changing page id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is my T:/ Drive, where the excel workbook is saved\n",
    "\n",
    "file = '{MYGOOGLEDOC}.xlsm'\n",
    "\n",
    "# Here I call the file, the sheet from the workbook, the dtype for the dataframe and the columns \n",
    "\n",
    "df = pd.read_excel(file, sheet_name=\"For Pull Data\", dtype = str, usecols= [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], na_filter = False, index_col= None)\n",
    "\n",
    "# This is a bit redundant but makes sure that the data in the dataframe is read as a 'string'\n",
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Whitespaces and commas <br>\n",
    "\n",
    "When data is pulled into pandas you should do a cleaning of the data. Python is sensitive to white spaces and tables can be sensitive to some special characters such as commas in the case of CSVs. Keep that in mind whenever performing tasks like this. \n",
    "\n",
    "`str.strip` is used in the function below. This is why it was so important to have the data in the dataframe read as a string. Now you'll see if you were to use `df.dtypes` you would see that each field is of dtype object. This is because there's some columns in the database I use that have both numbers and letters as well as some columns with large empty spaces. There is also a total row that appears at the bottom. All of these make it difficult for pandas to know if these of of type `str`, `int`, or something else so it chooses the catch-all `object`. Since we have the dataframe reading as a string, we can use the `.str` function and `.replace` function to clean up our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitespaceRemover(dataframe):\n",
    "    \n",
    "    # iterating over the columns\n",
    "    for i in dataframe.columns:\n",
    "          \n",
    "        # checking datatype of each columns\n",
    "        if dataframe[i].dtype == 'object': #helps pinpoint if something is wrong with the data type\n",
    "              \n",
    "            # applying strip function on column\n",
    "            dataframe[i] = dataframe[i].map(str.strip)\n",
    "            \n",
    "            dataframe[i] = dataframe[i].str.replace(\",\",\"\")\n",
    "            \n",
    "        else:\n",
    "              \n",
    "            # if condn. is False then it will do nothing.\n",
    "            pass\n",
    "            \n",
    "            print(f\"{i} was skipped because field value was not a string\")\n",
    "        \n",
    "### End Function ###\n",
    "\n",
    "print(\"Commas and whitespaces being removed...\")\n",
    "\n",
    "whitespaceRemover(df) # plug your dataframe into function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwriting Pull Data <br>\n",
    "\n",
    "After it's clean we can write it to a CSV file overwriting the previous pull data table in your survey. Notice the location of I am writing the new CSV to. The Media folder holds items used in various ArcGIS Survey123 workflows. The Media folder can contain offline basemaps that survey authors want downloaded with a specific survey in the ArcGIS Survey123 Field App. Additional workflows that use the Media folder include image questions that use the draw and annotate appearance, or consuming images directly in your survey. \n",
    "\n",
    "Please note that all care should be taken to ensure the files you are updating with this script have the exact same name as the files in the originally published media folder. Also, the files should have the same format, with the same field names as the original files (in the case of CSV files). Only rows of data should be updated or additional rows added. If you want to change the format of the files (rename or add columns) you should update the files via Connect in the media folder, update the survey XLS Form, and then re-publish the survey to ensure the changes do not break anything.\n",
    "\n",
    "It is recommended to test the script on a backup copy of your survey and ensure the survey can be downloaded and updated in the field app, checking that the external choice lists and/or media items are working as expected. This should be confirmed before running the script and updating the media folder and files on your real survey that is currently in use by other ArcGIS Survey123 Field App users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overwriting old Minerals Pulldata with cleaned Minerals Pulldata...\")\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\cschooley\\ArcGIS\\My Survey Designs\\PullUpdate\\MineralsPulldata.csv\", index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing Online Survey123 Pull Data with Local Update\n",
    "\n",
    "To start we will import the required modules and define our variables.<br>\n",
    "**Please format folder directories as C:/Users/username… include a trailing slash after the final folder name as the updated file directory is concatenated to the updated file name**\n",
    "\n",
    "\n",
    "The variables are defined as follows: \n",
    "\n",
    "* **portalURL** - The URL for your WebGIS Portal (ex. www.arcgis.com)\n",
    "* **username** - Your WebGIS Portal username (ex. gisadmin)\n",
    "* **password** - You WebGIS Portal password (ex. gisadmin1)\n",
    "* **itemID** - The Item ID for the ArcGIS Survey123 Form Item in you WebGIS Portal (ex. 89bc8c7844e548e09baa3aad4695e78b)\n",
    "* **download_folder** - The folder directory you would like the Survey123 Form Item to be downloaded with the trailing slash (ex. C:/temp/)\n",
    "* **updated_file** - The updated file name containing the extension (ex. pullData.csv)\n",
    "* **source_loc** - Folder directory where the updated file is located (ex. C:/users/username/arcgis/my survey designs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modules ###\n",
    "\n",
    "import arcgis\n",
    "from arcgis.gis import GIS\n",
    "import zipfile\n",
    "import shutil\n",
    "import arcpy\n",
    "import os\n",
    "\n",
    "token = arcpy.GetSigninToken()\n",
    "if token is not None:\n",
    "    print(token['token'])\n",
    "\n",
    "portalURL = r'https://arcgis.com'\n",
    "username = 'username'\n",
    "password = 'password'\n",
    "itemID = 'itemID'  \n",
    "download_folder = r'C:/temp/'\n",
    "updated_file = r'pullData.csv'\n",
    "source_loc = r'C:\\Users\\cschooley\\ArcGIS\\My Survey Designs\\PullUpdate/'# this is where mine is saved. PullUpdate is a custom folder I added\n",
    "\n",
    "\n",
    "### Connect to GIS ###\n",
    "\n",
    "gis = GIS(portalURL, username, password, verify_cert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the survey\n",
    "\n",
    "We will start by grabbing the properties of the Survey123 Form Item. These properties are used later when we update the Form Item with a zip file containing the new media content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_manager = arcgis.apps.survey123.SurveyManager(gis)\n",
    "surveyId = survey_manager.get(itemID)\n",
    "surveyProp = surveyId.properties\n",
    "\n",
    "# Find the Form item in the gis and download as a zip file to the *download_folder* directory.\n",
    "\n",
    "itm = arcgis.gis.Item(gis,itemID)\n",
    "print(itm)\n",
    "savedZip = itm.download(save_path=download_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the zip file to an *`_extracted`* folder in the download location.\n",
    "This *`_extracted`* folder is where the updated media files will be copied and rezipped later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractZIP(filename,folder):\n",
    "    zfile = zipfile.ZipFile(filename)\n",
    "    zfile.extractall(folder)\n",
    "\n",
    "extractZIP(savedZip, download_folder + \"_extracted/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the updated file to the media folder replacing the old file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = source_loc + updated_file\n",
    "dest_file = download_folder + \"_extracted/esriinfo/media/\" + updated_file\n",
    "shutil.copyfile(source_file, dest_file)\n",
    "print (updated_file + \" updated to: \" + download_folder + \"_extracted/esriinfo/media/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the old zip file that was previously downloaded. This will prevent any namespace issues and ensure the process of zipping and uploading the updated survey goes smoothly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(savedZip)\n",
    "print (\"Old zip file deleted from: \" + download_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the updated survey<br>\n",
    "\n",
    "We will now zip the updated survey and place it in the download folder. The code below grabs the survey title from the survey properties and passes it into the function which zips the updated survey contents to the download folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipFileName = surveyProp['title']\n",
    "os.chdir(download_folder)\n",
    "updateZip = shutil.make_archive(zipFileName, 'zip', download_folder + '_extracted/')\n",
    "print (updateZip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the new zip file and update the Form Item with the new Media folder content.\n",
    "\n",
    "Then, clean up intermediate data. This process will delete the updated zip file as well as the extracted folder containing the unzipped survey content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itm.update({},updateZip)\n",
    "\n",
    "os.remove(updateZip)\n",
    "print (zipFileName + \" deleted from: \" + download_folder)\n",
    "\n",
    "shutil.rmtree(download_folder + \"_extracted/\")\n",
    "print (\"extracted folder deleted from: \" + download_folder)\n",
    "print (zipFileName + \" successfully updated with \" + source_file + \" and uploaded to your ArcGIS portal!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Email Notifications\n",
    "\n",
    "This can also be done with a Google API that is safer and requires stricter authentication. Due to my organization's policies I used another work around. Be aware that using Yagmail requires you change some settings in your Gmail account. Here's an <a href = \"https://mailtrap.io/blog/yagmail-tutorial/\">article</a> to help you use Yagmail. Use this <a href = \"https://developers.google.com/gmail/api/guides/sending#python\">link</a> to find more information about the Gmail API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modules ###\n",
    "\n",
    "import yagmail\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Sending Emails...\")\n",
    "now = datetime.now()\n",
    "date = now.strftime(\"%m/%d/%Y\")\n",
    "time = now.strftime(\"%I:%M:%S %p\")\n",
    "reciever = ['email1', 'email2', 'email3']\n",
    "body = f'Hello,\\n\\n The {zipFileName} survey successfully updated with the latest Pulldata available as of {date} and uploaded to the {username}'s' account!\\n\\nCompleted on {date} at {time}.\\n\\nThank you!'\n",
    "yag = yagmail.SMTP(\"email\", 'password')\n",
    "for recipient in reciever:\n",
    "    yag.send(\n",
    "        to=recipient,\n",
    "        subject='subject',\n",
    "        contents = body\n",
    "    )\n",
    "\n",
    "print('Emails sent successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Cleaning Minerals Pull Data for Minerals Field Inspections\n",
    "\n",
    "# Cat Schooley  \n",
    "# GIS Analyst  \n",
    "# November 5, 2021\n",
    "# \n",
    "# ### Using Pull Data\n",
    "\n",
    "### import modules ###\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "### Remember the url format ###\n",
    "\n",
    "# \"https://docs.google.com/spreadsheets/d/{SPREADSHEETID}/export?format=csv&id{SPREADSHEETID}&gid=2113599541\"\n",
    "\n",
    "\n",
    "###### Uncomment this section to use URL instead of Google Drive Desktop ######\n",
    "\n",
    "# url = \"https://docs.google.com/spreadsheets/d/{SPREADSHEETIDENTIFIER}/export?format=csv&id{SPREADSHEETIDENTIFIER}&gid=2113599541\"\n",
    "\n",
    "\n",
    "# df = pd.read_csv(url, dtype = object, usecols= [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], na_filter = False)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\n",
    "\n",
    "###### Comment out this section to use URL instead of Google Drive Desktop ######\n",
    "\n",
    "file = '{MYGOOGLEDOC}.xlsm'\n",
    "\n",
    "\n",
    "df = pd.read_excel(file, sheet_name=\"For Pull Data\", dtype = str, usecols= [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], na_filter = False, index_col= None)\n",
    "\n",
    "########################################################################\n",
    "\n",
    "# Ensure dataframe is read as a 'string'\n",
    "df = df.astype(str)\n",
    "\n",
    "\n",
    "\n",
    "##### Remove Whitespaces and commas #####\n",
    "\n",
    "\n",
    "def whitespaceRemover(dataframe):\n",
    "    \n",
    "    # iterating over the columns\n",
    "    for i in dataframe.columns:\n",
    "          \n",
    "        # checking datatype of each columns\n",
    "        if dataframe[i].dtype == 'object': #helps pinpoint if something is wrong with the data type\n",
    "              \n",
    "            # applying strip function on column\n",
    "            dataframe[i] = dataframe[i].map(str.strip)\n",
    "            \n",
    "            dataframe[i] = dataframe[i].str.replace(\",\",\"\")\n",
    "            \n",
    "        else:\n",
    "              \n",
    "            # if condn. is False then it will do nothing.\n",
    "            pass\n",
    "            \n",
    "            print(f\"{i} was skipped because field value was not a string\")\n",
    "        \n",
    "### End Function ###\n",
    "\n",
    "print(\"Commas and whitespaces being removed...\")\n",
    "\n",
    "whitespaceRemover(df) # plug your dataframe into function\n",
    "\n",
    "\n",
    "##### Overwriting Pull Data #####\n",
    "\n",
    "\n",
    "print(\"Overwriting old Minerals Pulldata with cleaned Minerals Pulldata...\")\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\cschooley\\ArcGIS\\My Survey Designs\\PullUpdate\\MineralsPulldata.csv\", index = False) \n",
    "\n",
    "\n",
    "# #### Replacing Online Survey123 Pull Data with Local Update\n",
    "# \n",
    "# To start we will import the required modules and define our variables.<br>\n",
    "# **Please format folder directories as C:/Users/username… include a trailing slash after the final folder name as the updated file directory is concatenated to the updated file name**\n",
    "# \n",
    "# \n",
    "# The variables are defined as follows: \n",
    "# \n",
    "# * **portalURL** - The URL for your WebGIS Portal (ex. www.arcgis.com)\n",
    "# * **username** - Your WebGIS Portal username (ex. gisadmin)\n",
    "# * **password** - You WebGIS Portal password (ex. gisadmin1)\n",
    "# * **itemID** - The Item ID for the ArcGIS Survey123 Form Item in you WebGIS Portal (ex. 89bc8c7844e548e09baa3aad4695e78b)\n",
    "# * **download_folder** - The folder directory you would like the Survey123 Form Item to be downloaded with the trailing slash (ex. C:/temp/)\n",
    "# * **updated_file** - The updated file name containing the extension (ex. pullData.csv)\n",
    "# * **source_loc** - Folder directory where the updated file is located (ex. C:/users/username/arcgis/my survey designs/)\n",
    "\n",
    "\n",
    "\n",
    "### Modules ###\n",
    "\n",
    "import arcgis\n",
    "from arcgis.gis import GIS\n",
    "import zipfile\n",
    "import shutil\n",
    "import arcpy\n",
    "import os\n",
    "\n",
    "token = arcpy.GetSigninToken()\n",
    "if token is not None:\n",
    "    print(token['token'])\n",
    "\n",
    "portalURL = r'https://arcgis.com'\n",
    "username = 'username'\n",
    "password = 'password'\n",
    "itemID = 'itemID'  \n",
    "download_folder = r'C:/temp/'\n",
    "updated_file = r'pullData.csv'\n",
    "source_loc = r'C:\\Users\\cschooley\\ArcGIS\\My Survey Designs\\PullUpdate/'# this is where mine is saved. PullUpdate is a custom folder I added\n",
    "\n",
    "\n",
    "### Connect to GIS ###\n",
    "\n",
    "gis = GIS(portalURL, username, password, verify_cert=False)\n",
    "\n",
    "\n",
    "# #### Download the survey\n",
    "# \n",
    "# We will start by grabbing the properties of the Survey123 Form Item.\n",
    "# These properties are used later when we update the Form Item with a zip file\n",
    "# containing the new media content.\n",
    "\n",
    "survey_manager = arcgis.apps.survey123.SurveyManager(gis)\n",
    "surveyId = survey_manager.get(itemID)\n",
    "surveyProp = surveyId.properties\n",
    "\n",
    "# Find the Form item in the gis and download as a zip file to the\n",
    "# *download_folder* directory.\n",
    "\n",
    "itm = arcgis.gis.Item(gis,itemID)\n",
    "print(itm)\n",
    "savedZip = itm.download(save_path=download_folder)\n",
    "\n",
    "\n",
    "# Extract the zip file to an *`_extracted`* folder in the download location.\n",
    "# This *`_extracted`* folder is where the updated media files will be copied\n",
    "# and rezipped later on. \n",
    "\n",
    "def extractZIP(filename,folder):\n",
    "    zfile = zipfile.ZipFile(filename)\n",
    "    zfile.extractall(folder)\n",
    "\n",
    "extractZIP(savedZip, download_folder + \"_extracted/\")\n",
    "\n",
    "\n",
    "# Copy the updated file to the media folder replacing the old file. \n",
    "\n",
    "\n",
    "source_file = source_loc + updated_file\n",
    "dest_file = download_folder + \"_extracted/esriinfo/media/\" + updated_file\n",
    "shutil.copyfile(source_file, dest_file)\n",
    "print (updated_file + \" updated to: \" + download_folder + \"_extracted/esriinfo/media/\")\n",
    "\n",
    "\n",
    "# Delete the old zip file that was previously downloaded. This will prevent any namespace issues and ensure the process of zipping and uploading the updated survey goes smoothly. \n",
    "\n",
    "\n",
    "os.remove(savedZip)\n",
    "print (\"Old zip file deleted from: \" + download_folder)\n",
    "\n",
    "\n",
    "##### Upload the updated survey #####\n",
    "\n",
    "\n",
    "zipFileName = surveyProp['title']\n",
    "os.chdir(download_folder)\n",
    "updateZip = shutil.make_archive(zipFileName, 'zip', download_folder + '_extracted/')\n",
    "print (updateZip)\n",
    "\n",
    "\n",
    "# Upload the new zip file and update the Form Item with the new Media folder content.\n",
    "\n",
    "# Then, clean up intermediate data. This process will delete the updated zip file as well as the extracted folder containing the unzipped survey content.\n",
    "\n",
    "\n",
    "itm.update({},updateZip)\n",
    "\n",
    "os.remove(updateZip)\n",
    "print (zipFileName + \" deleted from: \" + download_folder)\n",
    "\n",
    "shutil.rmtree(download_folder + \"_extracted/\")\n",
    "print (\"extracted folder deleted from: \" + download_folder)\n",
    "print (zipFileName + \" successfully updated with \" + source_file + \" and uploaded to your ArcGIS portal!\")\n",
    "\n",
    "\n",
    "###### Send Email Notifications ######\n",
    "\n",
    "### Modules ###\n",
    "\n",
    "import yagmail\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Sending Emails...\")\n",
    "now = datetime.now()\n",
    "date = now.strftime(\"%m/%d/%Y\")\n",
    "time = now.strftime(\"%I:%M:%S %p\")\n",
    "reciever = ['email1', 'email2', 'email3']\n",
    "body = f'Hello,\\n\\n The {zipFileName} survey successfully updated with the latest Pulldata available as of {date} and uploaded to the {username}'s' account!\\n\\nCompleted on {date} at {time}.\\n\\nThank you!'\n",
    "yag = yagmail.SMTP(\"email\", 'password')\n",
    "for recipient in reciever:\n",
    "    yag.send(\n",
    "        to=recipient,\n",
    "        subject='subject',\n",
    "        contents = body\n",
    "    )\n",
    "\n",
    "print('Emails sent successfully.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
